{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuickStart_Dataset_HumanSperm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpcjNF4AGIZa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.applications.densenet import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NVPXBriwJdwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb2cbc69-0bb2-40ca-f72d-50e4f6cda550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dump(file_path, data, labels):\n",
        "    file = open(file_path, 'wb')\n",
        "    # dump information to that file\n",
        "    pickle.dump((data, labels), file)\n",
        "    # close the file\n",
        "    file.close()\n",
        "    pass\n",
        "\n",
        "\n",
        "def load_data(path_file):\n",
        "    file = open(path_file, 'rb')\n",
        "    # dump information to that file\n",
        "    (pixels, labels) = pickle.load(file)\n",
        "    # close the file\n",
        "    file.close()\n",
        "    print(pixels.shape)\n",
        "    print(labels.shape)\n",
        "    return pixels, labels\n",
        "\n",
        "\n",
        "def get_name_image(id, dfi, s, b):\n",
        "    name = 'img'\n",
        "    if id < 10:\n",
        "        name = name + '00' + str(id)\n",
        "    elif id < 100:\n",
        "        name = name + '0' + str(id)\n",
        "    else:\n",
        "        name = name + str(id)\n",
        "    dfi = round(dfi * 10000)\n",
        "    if dfi < 1000:\n",
        "        dfi = '0' + str(dfi)\n",
        "    name = name + '_' + s + '_' + b + '_DFI_' + str(dfi)\n",
        "    return name + '.jpg'\n",
        "\n",
        "\n",
        "def get_image(image_path):\n",
        "    # return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2GRAY)\n",
        "    # return cv2.imread(image_path)\n",
        "    # return cv2.resize(cv2.imread(image_path), dsize=(150, 150))\n",
        "    # print(image_path)\n",
        "    img = image.load_img(image_path, target_size=(150, 150, 3))\n",
        "    # plt.imshow(img)\n",
        "    return preprocess_input(image.img_to_array(img))\n",
        "\n",
        "\n",
        "def get_label(dfi):\n",
        "    if dfi < 0.1:\n",
        "        return 0\n",
        "    elif dfi < 0.15:\n",
        "        return 1\n",
        "    return 2\n",
        "\n",
        "\n",
        "def load_image(dataframe, path_local):\n",
        "    data_images = []\n",
        "    data_labels = []\n",
        "    for df in dataframe:\n",
        "        image_name = get_name_image(df[0], df[1], df[2], df[3])\n",
        "        image = get_image(path_local + image_name)\n",
        "        data_images.append(image)\n",
        "        data_labels.append(get_label(df[1]))\n",
        "    data_images = np.array(data_images)\n",
        "    data_labels = np.array(data_labels)\n",
        "    print(data_images.shape)\n",
        "    print(data_labels.shape)\n",
        "    return data_images, data_labels\n",
        "\n",
        "\n",
        "def view_chart(performance, people, chart):\n",
        "    fig, ax = plt.subplots()\n",
        "    y_pos = np.arange(len(people))\n",
        "    ax.barh(y_pos, performance, align='center', color=['green', 'yellowgreen', 'dodgerblue','orange'])\n",
        "    for index, value in enumerate(performance):\n",
        "        plt.text(value, index, str(value))\n",
        "    ax.set_yticks(y_pos)\n",
        "    ax.set_yticklabels(people)\n",
        "    ax.invert_yaxis()\n",
        "    ax.set_xlabel('Number')\n",
        "    ax.set_title(chart)\n",
        "    plt.xlim(0, max(performance) + 400)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def load_data_image_directory(CATEGORIES, DIRECTORY, size):\n",
        "    print(\"[INFO] loading images...\")\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for category in CATEGORIES:\n",
        "        path = os.path.join(DIRECTORY, category)\n",
        "        for img in os.listdir(path):\n",
        "            img_path = os.path.join(path, img)\n",
        "            image = load_img(img_path, target_size=size)\n",
        "            image = img_to_array(image)\n",
        "            image = preprocess_input(image)\n",
        "            data.append(image)\n",
        "            labels.append(category)\n",
        "\n",
        "    # perform one-hot encoding on the labels\n",
        "    # lb = LabelBinarizer()\n",
        "    # labels = lb.fit_transform(labels)\n",
        "    # labels = to_categorical(labels)\n",
        "\n",
        "    dataset = np.array(data, dtype=\"float32\")\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    data_train, data_test, labels_train, labels_test = train_test_split(dataset, labels, test_size=0.2, shuffle=True, \n",
        "                                                                        stratify=labels, random_state=100)\n",
        "    \n",
        "    train_data, valid_data, train_labels, valid_labels = train_test_split(data_train, labels_train, test_size=0.2, shuffle=True, \n",
        "                                                                          stratify=labels_train, random_state=100)\n",
        "    \n",
        "    return data_train, labels_train, train_data, train_labels, valid_data, valid_labels, data_test, labels_test"
      ],
      "metadata": {
        "id": "TAnAAfswN6P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset DFI\n",
        "csv_dfi_1_6 = '/content/drive/MyDrive/human_sperm_morphology_dataset/DFI_dataset/Donors1_6_cropped_with_DFI_labels/DFIs.csv'\n",
        "csv_dfi_7 = '/content/drive/MyDrive/human_sperm_morphology_dataset/DFI_dataset/Donor7_cropped_with_DFI_labels/DFIs.csv'\n",
        "local = '/content/drive/MyDrive/human_sperm_morphology_dataset/DFI_dataset/Donors1_6_cropped_with_DFI_labels/'\n",
        "\n",
        "df = np.array(pd.read_csv(csv_dfi_1_6, usecols=[0, 1, 4, 5], index_col=False))\n",
        "dataset, labels = load_image(df, local)\n",
        "data_train, data_test, labels_train, labels_test = train_test_split(dataset, labels, test_size=0.2,\n",
        "                                                                    shuffle=True, stratify=labels,\n",
        "                                                                    random_state=100)\n",
        "\n",
        "save_dump('/content/drive/MyDrive/human_sperm_morphology_dataset/DFI_dataset/DataImage_1_6/data_image_rgb_train.data', data_train, labels_train)\n",
        "save_dump('/content/drive/MyDrive/human_sperm_morphology_dataset/DFI_dataset/DataImage_1_6/data_image_rgb_test.data', data_test, labels_test)\n",
        "\n",
        "view_chart([sum(labels_train == 0), sum(labels_train == 1), sum(labels_train == 2)], \n",
        "           ['0', '1', '2'], 'Chart Data Train')\n",
        "\n",
        "view_chart([sum(labels_test == 0), sum(labels_test == 1), sum(labels_test == 2)], \n",
        "           ['0', '1', '2'], 'Chart Data Test')"
      ],
      "metadata": {
        "id": "bPdhibP-Jkhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset SMIDS\n",
        "DIRECTORY = \"/content/drive/MyDrive/human_sperm_morphology_dataset/SMIDS/Original\"\n",
        "CATEGORIES = [\"Abnormal_Sperm\", \"Non-Sperm\", \"Normal_Sperm\"]\n",
        "data_train, labels_train, train_data, train_labels, valid_data, valid_labels, data_test, labels_test = load_data_image_directory(CATEGORIES, DIRECTORY, (150, 150))\n",
        "# data_train.shape, labels_train.shape, train_data.shape, train_labels.shape, valid_data.shape, valid_labels.shape, data_test.shape, labels_test.shape\n",
        "\n",
        "DIRECTORY_GANs = \"/content/drive/MyDrive/human_sperm_morphology_dataset/SMIDS/GANs/1-1\"\n",
        "CATEGORIES_GANs = [\"Abnormal_Sperm\", \"Non-Sperm\", \"Normal_Sperm\"]\n",
        "data_train_gans, labels_train_gans, train_data_gans, train_labels_gans, valid_data_gans, valid_labels_gans, data_test_gans, labels_test_gans = load_data_image_directory(CATEGORIES_GANs, DIRECTORY_GANs, (150, 150))\n",
        "# data_train_gans.shape, labels_train_gans.shape, train_data_gans.shape, train_labels_gans.shape, valid_data_gans.shape, valid_labels_gans.shape, data_test_gans.shape, labels_test_gans.shape\n",
        "\n",
        "global_data_train = np.concatenate((data_train, data_train_gans), axis=0)\n",
        "global_labels_train = np.concatenate((labels_train, labels_train_gans), axis=None)\n",
        "\n",
        "global_train_data = np.concatenate((train_data, train_data_gans), axis=0)\n",
        "global_train_labels = np.concatenate((train_labels, train_labels_gans), axis=None)\n",
        "\n",
        "global_valid_data = np.concatenate((valid_data, valid_data_gans), axis=0)\n",
        "global_valid_labels = np.concatenate((valid_labels, valid_labels_gans), axis=None)\n",
        "\n",
        "global_data_test = np.concatenate((data_test, data_test_gans), axis=0)\n",
        "global_labels_test = np.concatenate((labels_test, labels_test_gans), axis=None)\n",
        "\n",
        "save_dump('/content/drive/MyDrive/human_sperm_morphology_dataset/SMIDS/dataset/smids_train.data', global_train_data, global_train_labels)\n",
        "save_dump('/content/drive/MyDrive/human_sperm_morphology_dataset/SMIDS/dataset/smids_valid.data', global_valid_data, global_valid_labels)\n",
        "save_dump('/content/drive/MyDrive/human_sperm_morphology_dataset/SMIDS/dataset/smids_datatrain.data', global_data_train, global_labels_train)\n",
        "save_dump('/content/drive/MyDrive/human_sperm_morphology_dataset/SMIDS/dataset/smids_datatest.data', global_data_test, global_labels_test)\n",
        "\n",
        "global_data_train.shape, global_labels_train.shape, global_train_data.shape, global_train_labels.shape, global_valid_data.shape, global_valid_labels.shape, global_data_test.shape, global_labels_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsJUVXC0IU64",
        "outputId": "9d502f31-6448-4971-f41c-30830063c280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading images...\n",
            "[INFO] loading images...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4808, 150, 150, 3),\n",
              " (4808,),\n",
              " (3846, 150, 150, 3),\n",
              " (3846,),\n",
              " (962, 150, 150, 3),\n",
              " (962,),\n",
              " (1202, 150, 150, 3),\n",
              " (1202,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset SCIAN\n",
        "\n",
        "DIRECTORY = \"/content/drive/MyDrive/human_sperm_morphology_dataset/SCIAN-Morpho/Original\"\n",
        "CATEGORIES = [\"01-Normal\", \"02-Tapered\", \"03-Pyriform\", \"04-Small\", \"05-Amorphous\"]\n",
        "data_train, labels_train, train_data, train_labels, valid_data, valid_labels, data_test, labels_test = load_data_image_directory(CATEGORIES, DIRECTORY, (33, 33))\n",
        "\n",
        "save_dump('/content/drive/MyDrive/human_sperm_morphology_dataset/SCIAN-Morpho/dataset/scian_train.data', train_data, train_labels)\n",
        "save_dump('/content/drive/MyDrive/human_sperm_morphology_dataset/SCIAN-Morpho/dataset/scian_valid.data', valid_data, valid_labels)\n",
        "\n",
        "save_dump('/content/drive/MyDrive/human_sperm_morphology_dataset/SCIAN-Morpho/dataset/scian_datatrain.data', data_train, labels_train)\n",
        "save_dump('/content/drive/MyDrive/human_sperm_morphology_dataset/SCIAN-Morpho/dataset/scian_datatest.data', data_test, labels_test)\n",
        "\n",
        "data_train.shape, labels_train.shape, train_data.shape, train_labels.shape, valid_data.shape, valid_labels.shape, data_test.shape, labels_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I5ashFZPAkc",
        "outputId": "29e4cb8e-a911-40e6-c8f5-7320bf9839d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading images...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11407, 33, 33, 3),\n",
              " (11407,),\n",
              " (9125, 33, 33, 3),\n",
              " (9125,),\n",
              " (2282, 33, 33, 3),\n",
              " (2282,),\n",
              " (2852, 33, 33, 3),\n",
              " (2852,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}